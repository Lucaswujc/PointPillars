{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a721ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff8e2419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_points(file_path, dim=4):\n",
    "    suffix = os.path.splitext(file_path)[1] \n",
    "    assert suffix in ['.bin', '.ply']\n",
    "    if suffix == '.bin':\n",
    "        return np.fromfile(file_path, dtype=np.float32).reshape(-1, dim)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def write_points(lidar_points, file_path):\n",
    "    suffix = os.path.splitext(file_path)[1] \n",
    "    assert suffix in ['.bin', '.ply']\n",
    "    if suffix == '.bin':\n",
    "        with open(file_path, 'w') as f:\n",
    "            lidar_points.tofile(f)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "def drop_points(points, drop_ratio):\n",
    "    \"\"\"\n",
    "    Randomly drops a fraction of points from the input numpy array.\n",
    "\n",
    "    Args:\n",
    "        points (np.ndarray): The input array of shape (N, D).\n",
    "        drop_ratio (float): Fraction of points to drop (between 0 and 1).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Array with dropped points.\n",
    "    \"\"\"\n",
    "    N = points.shape[0]\n",
    "    keep_num = int(N * (1 - drop_ratio))\n",
    "    indices = np.random.choice(N, keep_num, replace=False)\n",
    "    return points[indices]\n",
    "\n",
    "def process_validation_data(validation_file_path, output_file_path, deletion_ratio):\n",
    "    \"\"\"\n",
    "    Reads validation data from validation_file_path and processes each bin file\n",
    "    before saving the processed data to output_file_path.\n",
    "    \"\"\"\n",
    "    points = read_points(validation_file_path)\n",
    "    points = drop_points(points, deletion_ratio)\n",
    "    write_points(points, output_file_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f56c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_folder_structure(original_kitti_root, new_kitti_root, ratio):\n",
    "    folders = [\"calib\", \"image_2\", \"label_2\", \"velodyne\", \"velodyne_reduced\"]\n",
    "    ratio_dir = os.path.join(new_kitti_root, str(ratio))\n",
    "    os.makedirs(ratio_dir, exist_ok=True)\n",
    "    pickle_files = glob.glob(os.path.join(original_kitti_root, \"*.pkl\"))    \n",
    "    for file_path in pickle_files:\n",
    "        shutil.copy2(file_path, ratio_dir)\n",
    "    ratio_dir = os.path.join(ratio_dir, \"training\")\n",
    "    os.makedirs(ratio_dir, exist_ok=True)\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(ratio_dir, folder)\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "    return ratio_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36469d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = [0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "validation_text = \"/home/lucas/repos/PointPillars/pointpillars/dataset/ImageSets/val.txt\"\n",
    "training_bin_file_prefix = \"/home/lucas/repos/PointPillars/kitti/training/velodyne_reduced\"\n",
    "with open(validation_text, 'r') as file:\n",
    "    validation_filenames = file.readlines()\n",
    "for ratio in ratios:\n",
    "    output_file_prefix = prepare_folder_structure(\"/home/lucas/repos/PointPillars/kitti\", \n",
    "                             \"/home/lucas/repos/PointPillars/kitti_deleted\", \n",
    "                             ratio)\n",
    "    for file_name in validation_filenames:\n",
    "        input_path = os.path.join(training_bin_file_prefix, file_name.strip() + \".bin\")\n",
    "        output_path = os.path.join(output_file_prefix,\"velodyne_reduced\", f\"{file_name.strip()}.bin\")\n",
    "        points = process_validation_data(input_path, output_path, ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13938c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "001610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "path = \"/home/lucas/repos/PointPillars/pointpillars/dataset/ImageSets/val.txt\"\n",
    "\n",
    "with open(path, 'r') as f:\n",
    "    data = f.readlines()\n",
    "print(data[805])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad94f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pointpillars.dataset import Kitti, get_dataloader\n",
    "val_dataset = Kitti(data_root=\"/home/lucas/repos/PointPillars/kitti_deleted/0.6\",\n",
    "                        split='val')\n",
    "val_dataloader = get_dataloader(dataset=val_dataset, \n",
    "                                    batch_size=1, \n",
    "                                    num_workers=4,\n",
    "                                    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0633ae80",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m batch_results\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, data_dict_original \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtdqm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m805\u001b[39m:\n\u001b[1;32m     12\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data_dict_original:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pointpillars.model import PointPillars\n",
    "import tqdm\n",
    "data_dict = {}\n",
    "model = PointPillars(nclasses=3).cuda()\n",
    "model.load_state_dict(torch.load(\"pretrained/epoch_160.pth\"))\n",
    "model.eval()\n",
    "batch_results= None\n",
    "with torch.no_grad():\n",
    "    for i, data_dict_original in enumerate(tqdm(val_dataloader)):\n",
    "        if i == 805:\n",
    "            for key in data_dict_original:\n",
    "                for j, item in enumerate(data_dict_original[key]):\n",
    "                    if torch.is_tensor(item):\n",
    "                        data_dict_original[key][j] = data_dict_original[key][j].cuda()\n",
    "            data_dict = data_dict_original\n",
    "            break\n",
    "    batched_pts = data_dict['batched_pts']\n",
    "    batched_gt_bboxes = data_dict['batched_gt_bboxes']\n",
    "    batched_labels = data_dict['batched_labels']\n",
    "    batched_difficulty = data_dict['batched_difficulty']\n",
    "    batch_results = model(batched_pts=batched_pts, \n",
    "                    mode='val',\n",
    "                    batched_gt_bboxes=batched_gt_bboxes, \n",
    "                    batched_gt_labels=batched_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "043ece68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[{'lidar_bboxes': array([[19.579243  , -2.7978206 , -0.8521094 ,  0.6657081 ,  0.69728935,\n",
      "         1.7805387 , -3.005843  ],\n",
      "       [ 8.807708  , -3.1225326 , -0.9373024 ,  0.5085847 ,  0.70824975,\n",
      "         1.7090148 ,  2.6683772 ],\n",
      "       [ 6.2004294 , -2.8211627 , -1.6241834 ,  1.5427153 ,  3.5344758 ,\n",
      "         1.4514694 , -1.6109692 ],\n",
      "       [12.602291  ,  4.224052  , -1.806828  ,  1.5235919 ,  3.578537  ,\n",
      "         1.4078885 , -1.6159204 ],\n",
      "       [16.573448  , -2.6436632 , -1.520259  ,  1.5907251 ,  3.5249205 ,\n",
      "         1.4694097 , -1.5625604 ],\n",
      "       [21.662922  ,  4.519707  , -1.65463   ,  1.6430291 ,  4.2045426 ,\n",
      "         1.609315  , -1.5237412 ],\n",
      "       [35.644783  ,  4.969858  , -1.6814785 ,  1.6142138 ,  4.065442  ,\n",
      "         1.522496  ,  1.588921  ],\n",
      "       [32.204247  , -2.514601  , -1.5472792 ,  1.5590453 ,  3.577557  ,\n",
      "         1.5262825 , -1.6000888 ],\n",
      "       [51.65022   ,  5.2891026 , -1.8894546 ,  1.5902733 ,  4.1205297 ,\n",
      "         1.5710205 ,  1.5516531 ]], dtype=float32), 'labels': array([0, 0, 2, 2, 2, 2, 2, 2, 2]), 'scores': array([0.474437  , 0.3913495 , 0.9652215 , 0.9563726 , 0.9130995 ,\n",
      "       0.839148  , 0.76419735, 0.74697685, 0.3158257 ], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "print(type(batch_results))\n",
    "print(batch_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660d82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, result in enumerate(batch_results):\n",
    "    if type(result) != dict:\n",
    "        print(f\"Result {j} is a {type(result)}\") \n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34388d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PointPillars",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
